{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa9be8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import HuggingFaceHub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5d2edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec067818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF documents\n",
    "def load_and_split_pdf(pdf_path):\n",
    "    \"\"\"Loads a PDF and splits it into chunks.\"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6edec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings and Vector Store (ChromaDB)\n",
    "def create_vectorstore(\n",
    "    texts,\n",
    "    embeddings_model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    persist_directory=\"chroma_db\",\n",
    "):\n",
    "    \"\"\"Creates a Chroma vector store from text chunks.\"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=texts, embedding=embeddings, persist_directory=persist_directory\n",
    "    )\n",
    "    vectorstore.persist()  # Persist the database to disk.\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ae94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Pipeline\n",
    "def create_rag_pipeline(\n",
    "    vectorstore, model_id=\"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "):  # Or other HF LLMs\n",
    "    \"\"\"Creates a RetrievalQA pipeline for RAG.\"\"\"\n",
    "    llm = HuggingFacePipeline.from_model_id(\n",
    "        model_id=model_id,\n",
    "        task=\"text-generation\",\n",
    "        pipeline_kwargs={\"temperature\": 0.1, \"max_length\": 512},\n",
    "    )  # Adjust temperature and max_length as needed.\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever()\n",
    "    )\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a44d7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def rag_pdf_qa(\n",
    "    pdf_path,\n",
    "    question,\n",
    "    embeddings_model=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    llm_model=\"HuggingFaceTB/SmolLM2-1.7B-Instruct\",\n",
    "):\n",
    "    \"\"\"Performs RAG on a PDF and answers a question.\"\"\"\n",
    "    texts = load_and_split_pdf(pdf_path)\n",
    "    vectorstore = create_vectorstore(texts, embeddings_model)\n",
    "    qa = create_rag_pipeline(vectorstore, llm_model)\n",
    "    result = qa.invoke(question)\n",
    "    return result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7f46af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/aws-overview.pdf\"\n",
    "question = \"What are the main topics discussed in this document?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d365411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Got device==0, device is required to be within [-1, 0)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    answer = rag_pdf_qa(pdf_path, question)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: PDF file not found at {pdf_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ace4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
